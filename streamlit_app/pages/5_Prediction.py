import streamlit as st
import pandas as pd
import numpy as np
import os
import sys
import matplotlib.pyplot as plt
import seaborn as sns
import joblib
from datetime import datetime

# ModÃ¼lleri import et
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.preprocessing import load_data
from utils.model_utils import list_available_models, load_model, apply_model_preprocessing
from utils.visualizations import plot_feature_importance

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="Tahmin",
    page_icon="ðŸ”®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ana baÅŸlÄ±k
st.title("ðŸ”® Meme Kanseri TeÅŸhis Tahmini")

# Tahmin iÃ§in veri yÃ¼kleme fonksiyonu
def get_prediction_data(model_feature_names=None, columns_to_drop=None, scaler=None):
    """Tahmin iÃ§in veri yÃ¼kleme fonksiyonu"""
    
    data_source = st.radio(
        "Veri KaynaÄŸÄ±",
        ["Ã–rnek Veri", "Elle GiriÅŸ", "CSV DosyasÄ± YÃ¼kle"]
    )
    
    if data_source == "Ã–rnek Veri":
        df = load_data()
        
        # Ã–rnek veri iÃ§in bir satÄ±r seÃ§
        selected_example = st.slider("Ã–rnek SatÄ±r SeÃ§in", min_value=0, max_value=len(df)-1, value=0)
        
        # Hedef sÃ¼tunu ayÄ±r
        X = df.drop('target', axis=1) if 'target' in df.columns else df
        y = df['target'] if 'target' in df.columns else None
        
        # EÄŸitim sÄ±rasÄ±nda Ã§Ä±karÄ±lan sÃ¼tunlarÄ± burada da Ã§Ä±kar
        if columns_to_drop and len(columns_to_drop) > 0:
            available_columns = list(X.columns)
            columns_to_drop_available = [col for col in columns_to_drop if col in available_columns]
            if columns_to_drop_available:
                X = X.drop(columns=columns_to_drop_available)
                st.info(f"Model eÄŸitimi sÄ±rasÄ±nda Ã§Ä±karÄ±lan sÃ¼tunlar Ã¶rnek veriden de Ã§Ä±karÄ±ldÄ±: {', '.join(columns_to_drop_available)}")
        
        # SeÃ§ilen satÄ±rÄ± al
        example_data = X.iloc[selected_example:selected_example+1].copy()
        true_label = y.iloc[selected_example] if y is not None else None
        
        return example_data, true_label, list(X.columns)
    
    elif data_source == "Elle GiriÅŸ":
        st.info("LÃ¼tfen aÅŸaÄŸÄ±daki Ã¶zelliklerin deÄŸerlerini girin:")
        
        # Model Ã¶zellik isimlerini kullan (eÄŸer varsa), yoksa Ã¶rnek veriden al
        if model_feature_names and len(model_feature_names) > 0:
            feature_names = model_feature_names
            # Ã–rnek veri istatistikleri iÃ§in
            df = load_data()
            X = df.drop('target', axis=1) if 'target' in df.columns else df
            # EÄŸitim sÄ±rasÄ±nda Ã§Ä±karÄ±lan sÃ¼tunlarÄ± burada da Ã§Ä±kar
            if columns_to_drop and len(columns_to_drop) > 0:
                available_columns = list(X.columns)
                columns_to_drop_available = [col for col in columns_to_drop if col in available_columns]
                if columns_to_drop_available:
                    X = X.drop(columns=columns_to_drop_available)
        else:
            # Ã–rnek veriyi yÃ¼kle ve Ã¶zellik isimlerini al
            df = load_data()
            X = df.drop('target', axis=1) if 'target' in df.columns else df
            feature_names = list(X.columns)
        
        # Sadece mevcut Ã¶zelliklerin istatistiklerini hesapla
        available_features = [f for f in feature_names if f in X.columns]
        if len(available_features) != len(feature_names):
            st.warning(f"BazÄ± Ã¶zellikler mevcut deÄŸil. Sadece {len(available_features)}/{len(feature_names)} Ã¶zellik kullanÄ±labilir.")
            feature_names = available_features
        
        # Ã–zellikler iÃ§in Ã¶rnek istatistikleri hesapla
        feature_stats = X[feature_names].describe().T[['mean', 'min', 'max']]
        
        # KullanÄ±cÄ± giriÅŸi iÃ§in 3 sÃ¼tunlu dÃ¼zen
        col1, col2, col3 = st.columns(3)
        
        user_input = {}
        for i, feature in enumerate(feature_names):
            # Hangi sÃ¼tunda gÃ¶sterileceÄŸini belirle
            col_idx = i % 3
            col = [col1, col2, col3][col_idx]
            
            # Min, max ve ortalama deÄŸerleri al
            feat_min = float(feature_stats.loc[feature, 'min'])
            feat_max = float(feature_stats.loc[feature, 'max'])
            feat_mean = float(feature_stats.loc[feature, 'mean'])
            
            # KullanÄ±cÄ±dan deÄŸer iste
            with col:
                user_input[feature] = st.number_input(
                    f"{feature}",
                    min_value=float(feat_min * 0.5),
                    max_value=float(feat_max * 1.5),
                    value=float(feat_mean),
                    step=float((feat_max - feat_min) / 100),
                    format="%.4f"
                )
        
        # KullanÄ±cÄ± giriÅŸlerini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
        example_data = pd.DataFrame([user_input])
        return example_data, None, feature_names
    
    else:  # CSV DosyasÄ± YÃ¼kle
        uploaded_file = st.file_uploader("CSV dosyasÄ± yÃ¼kleyin", type=["csv"])
        
        if uploaded_file is not None:
            try:
                df = pd.read_csv(uploaded_file)
                st.success(f"{uploaded_file.name} baÅŸarÄ±yla yÃ¼klendi!")
                
                # Veriyi gÃ¶ster
                st.dataframe(df.head(), use_container_width=True)
                
                # EÄŸer birden fazla satÄ±r varsa kullanÄ±cÄ±ya hangi satÄ±rÄ±n tahmin edileceÄŸini seÃ§
                if len(df) > 1:
                    selected_row = st.slider("Tahmin Edilecek SatÄ±rÄ± SeÃ§in", min_value=0, max_value=len(df)-1, value=0)
                    example_data = df.iloc[selected_row:selected_row+1].copy()
                else:
                    example_data = df.copy()
                
                # EÄŸer 'target' sÃ¼tunu varsa, onu ayÄ±r
                if 'target' in example_data.columns:
                    true_label = example_data['target'].iloc[0]
                    example_data = example_data.drop('target', axis=1)
                else:
                    true_label = None
                
                # EÄŸitim sÄ±rasÄ±nda Ã§Ä±karÄ±lan sÃ¼tunlarÄ± burada da Ã§Ä±kar
                if columns_to_drop and len(columns_to_drop) > 0:
                    available_columns = list(example_data.columns)
                    columns_to_drop_available = [col for col in columns_to_drop if col in available_columns]
                    if columns_to_drop_available:
                        example_data = example_data.drop(columns=columns_to_drop_available)
                        st.info(f"Model eÄŸitimi sÄ±rasÄ±nda Ã§Ä±karÄ±lan sÃ¼tunlar CSV verisinden de Ã§Ä±karÄ±ldÄ±: {', '.join(columns_to_drop_available)}")
                
                return example_data, true_label, list(example_data.columns)
                
            except Exception as e:
                st.error(f"Dosya yÃ¼klenirken hata oluÅŸtu: {str(e)}")
                return None, None, None
        else:
            st.info("LÃ¼tfen bir CSV dosyasÄ± yÃ¼kleyin.")
            return None, None, None

# Modelleri yÃ¼kle
try:
    available_models = list_available_models()
    
    # TÃ¼m modelleri birleÅŸtir
    all_models = available_models["ready"] + available_models["custom"]
    
    # EÄŸer model yoksa uyarÄ± ver
    if len(all_models) == 0:
        st.warning("""
        Åžu an iÃ§in hiÃ§ model bulunmuyor. 
        'Model EÄŸitimi' sayfasÄ±nÄ± kullanarak model eÄŸitebilirsiniz veya 'HazÄ±r Modeller' sayfasÄ±ndan demo modelleri deneyebilirsiniz.
        """)
        st.stop()
    
    # Sidebar - Model SeÃ§imi
    st.sidebar.header("Tahmin AyarlarÄ±")
    
    # Model seÃ§imi
    selected_model_name = st.sidebar.selectbox(
        "Tahmin iÃ§in Model SeÃ§in",
        options=[model["name"] for model in all_models],
        index=0
    )
    
    # SeÃ§ilen modeli bul
    selected_model_info = next((model for model in all_models if model["name"] == selected_model_name), None)
    
    if selected_model_info:
        # Modelin kategorisini belirle
        model_category = "ready" if selected_model_info in available_models["ready"] else "custom"
        
        # Demo modeller iÃ§in Ã¶zel durum
        is_demo = "demo" in selected_model_name
        
        # Model bilgilerini gÃ¶ster
        st.sidebar.subheader("SeÃ§ilen Model Bilgileri")
        st.sidebar.write(f"**Model AdÄ±:** {selected_model_info['name']}")
        st.sidebar.write(f"**Model TÃ¼rÃ¼:** {selected_model_info['type']}")
        st.sidebar.write(f"**DoÄŸruluk (Accuracy):** {selected_model_info['accuracy']:.4f}")
        
        # Tahmin eÅŸiÄŸi ayarÄ± (binary sÄ±nÄ±flandÄ±rma iÃ§in)
        threshold = st.sidebar.slider(
            "Tahmin EÅŸiÄŸi",
            min_value=0.0,
            max_value=1.0,
            value=0.5,
            step=0.05,
            help="Pozitif sÄ±nÄ±f (malignant) iÃ§in tahmin eÅŸiÄŸi."
        )
        
        # Model preprocessing bilgilerini al (eÄŸer custom model ise)
        model_feature_names = None
        columns_to_drop = []
        has_preprocessing_info = False
        
        if model_category == "custom":
            try:
                # Sadece preprocessing bilgilerini al
                _, _, _, preprocessing_info, _ = load_model(selected_model_name, directory=f"models/{model_category}")
                model_feature_names = preprocessing_info.get("feature_names", None)
                columns_to_drop = preprocessing_info.get("columns_to_drop", [])
                scaler_type = preprocessing_info.get("scaler_type", "StandardScaler")
                
                # EÄŸer preprocessing bilgisi varsa
                if preprocessing_info and (model_feature_names or columns_to_drop):
                    has_preprocessing_info = True
                    if columns_to_drop:
                        st.sidebar.info(f"Bu model eÄŸitilirken ÅŸu sÃ¼tunlar Ã§Ä±karÄ±lmÄ±ÅŸtÄ±: {', '.join(columns_to_drop)}")
                    st.sidebar.info(f"Bu model eÄŸitilirken kullanÄ±lan scaler: {scaler_type}")
                
            except:
                # Eski modeller iÃ§in preprocessing bilgisi olmayabilir
                pass
        
        # EÄŸer eski model ise manuel preprocessing ayarlarÄ± gÃ¶ster
        if model_category == "custom" and not has_preprocessing_info:
            st.sidebar.warning("âš ï¸ Bu model eski bir model olduÄŸu iÃ§in preprocessing bilgileri mevcut deÄŸil.")
            
            # Ã–rnek veriyi yÃ¼kle
            sample_df = load_data()
            available_columns = [col for col in sample_df.columns if col != 'target']
            
            # Manuel olarak Ã§Ä±karÄ±lacak sÃ¼tunlarÄ± seÃ§
            st.sidebar.subheader("Manuel Preprocessing AyarlarÄ±")
            manual_columns_to_drop = st.sidebar.multiselect(
                "Bu modelin eÄŸitiminde Ã§Ä±karÄ±lan sÃ¼tunlarÄ± seÃ§in",
                options=available_columns,
                default=[],
                help="EÄŸer bu model eÄŸitilirken bazÄ± sÃ¼tunlar Ã§Ä±karÄ±ldÄ±ysa, burada seÃ§in."
            )
            
            if manual_columns_to_drop:
                columns_to_drop = manual_columns_to_drop
                st.sidebar.success(f"SeÃ§ilen {len(columns_to_drop)} sÃ¼tun tahmin verisinden Ã§Ä±karÄ±lacak.")
            
            # Model iÃ§in preprocessing bilgilerini gÃ¼ncelleme seÃ§eneÄŸi
            if st.sidebar.button("Bu Bilgileri Modele Kaydet", help="Bu preprocessing ayarlarÄ±nÄ± modele kalÄ±cÄ± olarak kaydeder."):
                try:
                    # Modeli yeniden yÃ¼kle
                    model, model_info, metrics, old_preprocessing_info, old_scaler = load_model(selected_model_name, directory=f"models/{model_category}")
                    
                    # Yeni preprocessing bilgilerini hazÄ±rla
                    updated_preprocessing_info = {
                        "columns_to_drop": columns_to_drop,
                        "target_column": "target",  # VarsayÄ±lan
                        "feature_names": [col for col in available_columns if col not in columns_to_drop],
                        "test_size": 0.2,  # VarsayÄ±lan
                        "scaler_type": "StandardScaler"  # VarsayÄ±lan
                    }
                    
                    # Modeli gÃ¼ncellenen bilgilerle yeniden kaydet
                    save_model(model, model_info, metrics, selected_model_name, 
                             directory=f"models/{model_category}", 
                             preprocessing_info=updated_preprocessing_info,
                             scaler=old_scaler)
                    
                    st.sidebar.success("Model preprocessing bilgileri gÃ¼ncellendi! SayfayÄ± yenileyin.")
                    
                except Exception as e:
                    st.sidebar.error(f"Model gÃ¼ncellenirken hata: {str(e)}")
        
        elif model_category == "ready":
            # HazÄ±r modeller iÃ§in demo uyarÄ±sÄ±
            if "demo" in selected_model_name:
                st.sidebar.info("Demo modelleri iÃ§in preprocessing bilgisi mevcut deÄŸil.")
        
        # Tahmin iÃ§in veri al
        st.header("Tahmin iÃ§in Veri")
        
        # Model scaler'Ä±nÄ± al (eÄŸer custom model ise)
        model_scaler_for_input = None
        if model_category == "custom" and has_preprocessing_info:
            try:
                _, _, _, _, model_scaler_for_input = load_model(selected_model_name, directory=f"models/{model_category}")
            except:
                pass
        
        example_data, true_label, feature_names = get_prediction_data(model_feature_names, columns_to_drop, model_scaler_for_input)
        
        if example_data is not None and len(example_data) > 0:
            st.subheader("Tahmin Edilecek Veri")
            st.dataframe(example_data, use_container_width=True)
            
            # Tahmin butonu
            predict_button = st.button("Tahmin Et", type="primary")
            
            if predict_button:
                st.header("Tahmin SonuÃ§larÄ±")
                
                # Demo modeller iÃ§in rastgele tahmin
                if is_demo:
                    # Rastgele bir olasÄ±lÄ±k Ã¼ret
                    np.random.seed(int(datetime.now().timestamp()) % 10000)
                    probability = np.random.beta(5, 2)  # Genellikle yÃ¼ksek olasÄ±lÄ±k Ã¼retir
                    prediction = 1 if probability > threshold else 0
                    
                    st.subheader("Model Tahmini")
                    
                    # SÄ±nÄ±f etiketi
                    label = "Malignant (KÃ¶tÃ¼ Huylu)" if prediction == 1 else "Benign (Ä°yi Huylu)"
                    label_color = "red" if prediction == 1 else "green"
                    
                    # Tahmin sonucunu gÃ¶ster
                    st.markdown(f"<h3 style='color: {label_color};'>Tahmin: {label}</h3>", unsafe_allow_html=True)
                    
                    # OlasÄ±lÄ±k Ã§ubuÄŸu
                    st.subheader("Tahmin OlasÄ±lÄ±ÄŸÄ±")
                    st.progress(float(probability))
                    st.write(f"KÃ¶tÃ¼ Huylu (Malignant) OlasÄ±lÄ±ÄŸÄ±: {probability:.2%}")
                    
                    # EÄŸer gerÃ§ek etiket varsa gÃ¶ster
                    if true_label is not None:
                        true_class = "Malignant (KÃ¶tÃ¼ Huylu)" if true_label == 1 else "Benign (Ä°yi Huylu)"
                        st.write(f"**GerÃ§ek SÄ±nÄ±f:** {true_class}")
                    
                    # Demo modeller iÃ§in rassal Ã¶zellik Ã¶nemi
                    st.subheader("Ã–zellik Ã–nemi (Demo)")
                    
                    # Rastgele Ã¶nem puanlarÄ± oluÅŸtur
                    np.random.seed(42)  # Tekrarlanabilirlik iÃ§in
                    feature_importance = pd.DataFrame({
                        "feature": feature_names,
                        "importance": np.random.rand(len(feature_names))
                    }).sort_values("importance", ascending=False)
                    
                    # Ã–zellik Ã¶nemini gÃ¶rselleÅŸtir
                    fig = plt.figure(figsize=(10, 6))
                    plt.barh(feature_importance['feature'], feature_importance['importance'])
                    plt.xlabel('Ã–nem Derecesi')
                    plt.ylabel('Ã–zellik')
                    plt.title('Ã–zellik Ã–nemi')
                    plt.tight_layout()
                    st.pyplot(fig)
                    
                else:
                    try:
                        # GerÃ§ek modeli yÃ¼kle
                        model, model_info, metrics, preprocessing_info, model_scaler = load_model(selected_model_name, directory=f"models/{model_category}")
                        
                        # Veriyi modelin beklediÄŸi formata getir (preprocessing uygula)
                        example_data_processed = apply_model_preprocessing(example_data, preprocessing_info, model_scaler)
                        
                        if example_data_processed.shape[0] > 0:
                            st.info(f"Veri preprocessing uygulandÄ±. Boyut: {example_data_processed.shape}")
                            
                            # EÄŸitimde Ã§Ä±karÄ±lan sÃ¼tunlar hakkÄ±nda bilgi ver
                            if preprocessing_info and preprocessing_info.get("columns_to_drop"):
                                dropped_cols = preprocessing_info["columns_to_drop"]
                                st.info(f"Model eÄŸitiminde Ã§Ä±karÄ±lan sÃ¼tunlar tahmin verisinden de Ã§Ä±karÄ±ldÄ±: {', '.join(dropped_cols)}")
                        else:
                            st.warning("Preprocessing uygulandÄ±ktan sonra veri boyutu sÄ±fÄ±r oldu.")
                        
                        # Modelin tÃ¼rÃ¼ne gÃ¶re tahmin yap
                        if model_info["type"] == "neural_network":
                            probabilities = model.predict(example_data_processed).ravel()
                            prediction = (probabilities > threshold).astype(int)
                        else:  # classical model
                            prediction = model.predict(example_data_processed)
                            
                            if hasattr(model, "predict_proba"):
                                probabilities = model.predict_proba(example_data_processed)[:, 1]
                            elif hasattr(model, "decision_function"):
                                # SVM gibi modeller iÃ§in karar fonksiyonunu olasÄ±lÄ±ÄŸa dÃ¶nÃ¼ÅŸtÃ¼r
                                decision_values = model.decision_function(example_data_processed)
                                probabilities = 1 / (1 + np.exp(-decision_values))
                            else:
                                probabilities = prediction.astype(float)
                        
                        st.subheader("Model Tahmini")
                        
                        # SÄ±nÄ±f etiketi
                        label = "Malignant (KÃ¶tÃ¼ Huylu)" if prediction[0] == 1 else "Benign (Ä°yi Huylu)"
                        label_color = "red" if prediction[0] == 1 else "green"
                        
                        # Tahmin sonucunu gÃ¶ster
                        st.markdown(f"<h3 style='color: {label_color};'>Tahmin: {label}</h3>", unsafe_allow_html=True)
                        
                        # OlasÄ±lÄ±k Ã§ubuÄŸu
                        st.subheader("Tahmin OlasÄ±lÄ±ÄŸÄ±")
                        st.progress(float(probabilities[0]))
                        st.write(f"KÃ¶tÃ¼ Huylu (Malignant) OlasÄ±lÄ±ÄŸÄ±: {float(probabilities[0]):.2%}")
                        
                        # EÄŸer gerÃ§ek etiket varsa gÃ¶ster
                        if true_label is not None:
                            true_class = "Malignant (KÃ¶tÃ¼ Huylu)" if true_label == 1 else "Benign (Ä°yi Huylu)"
                            st.write(f"**GerÃ§ek SÄ±nÄ±f:** {true_class}")
                        
                        # SHAP deÄŸerleri yerine Ã¶zellik Ã¶nemi gÃ¶ster (eÄŸer model destekliyorsa)
                        if model_info["type"] != "neural_network" and model_info["type"] not in ["knn"]:
                            from utils.model_utils import calculate_feature_importance
                            
                            st.subheader("Ã–zellik Ã–nemi")
                            
                            # Ã–zellik Ã¶nemini hesapla
                            feature_importance = calculate_feature_importance(
                                model, 
                                feature_names, 
                                "classical" if model_info["type"] != "neural_network" else "neural_network"
                            )
                            
                            # Ã–zellik Ã¶nemini gÃ¶rselleÅŸtir
                            importance_fig = plot_feature_importance(feature_importance)
                            st.pyplot(importance_fig)
                        
                    except Exception as e:
                        st.error(f"Tahmin yapÄ±lÄ±rken bir hata oluÅŸtu: {str(e)}")
                        st.exception(e)
            
    else:
        st.error("SeÃ§ilen model bulunamadÄ±.")

except Exception as e:
    st.error(f"Modeller listelenirken bir hata oluÅŸtu: {str(e)}")
    st.exception(e)
