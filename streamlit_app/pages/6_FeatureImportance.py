import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import os
import sys
import seaborn as sns
from sklearn.ensemble import RandomForestClassifier
from sklearn.inspection import permutation_importance

# ModÃ¼lleri import et
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from utils.preprocessing import load_data, preprocess_data
from utils.model_utils import list_available_models, load_model, calculate_feature_importance
from utils.visualizations import (
    plot_feature_importance, plot_correlation_heatmap, 
    plot_interactive_feature_importance, plot_pca_visualization
)

# Sayfa konfigÃ¼rasyonu
st.set_page_config(
    page_title="Ã–zellik Ã–nemi",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ana baÅŸlÄ±k
st.title("ğŸ“Š Ã–zellik Ã–nemi ve Veri Ä°liÅŸkileri")

# Veriyi yÃ¼kle
df = load_data()

# Hedef sÃ¼tunu ayÄ±r
X = df.drop('target', axis=1) if 'target' in df.columns else df
y = df['target'] if 'target' in df.columns else None

# Ã–zellik isimlerini al
feature_names = list(X.columns)

# Sidebar - Analiz SeÃ§enekleri
st.sidebar.header("Analiz SeÃ§enekleri")

analysis_type = st.sidebar.radio(
    "Analiz TÃ¼rÃ¼",
    ["Model BazlÄ± Ã–zellik Ã–nemi", "Korelasyon Analizi", "Ã–zellik DaÄŸÄ±lÄ±mlarÄ±", "Boyut Ä°ndirgeme"]
)

if analysis_type == "Model BazlÄ± Ã–zellik Ã–nemi":
    st.header("Model BazlÄ± Ã–zellik Ã–nemi Analizi")
    
    # Analiz yÃ¶ntemi seÃ§imi
    method = st.radio(
        "Ã–zellik Ã–nemi YÃ¶ntemi",
        ["Random Forest Ä°Ã§in Hesapla", "PermÃ¼tasyon Ã–nemi"]
    )
    
    # Random Forest ile Ã¶zellik Ã¶nemi hesaplama
    if method == "Random Forest Ä°Ã§in Hesapla":
        st.subheader("Random Forest Ã–zellik Ã–nemi")
        
        # Model parametreleri
        col1, col2 = st.columns(2)
        with col1:
            n_estimators = st.slider("AÄŸaÃ§ SayÄ±sÄ±", min_value=10, max_value=200, value=100, step=10)
        with col2:
            max_depth = st.slider("Maksimum Derinlik", min_value=2, max_value=20, value=10, step=1)
        
        # Random Forest modeli eÄŸit
        with st.spinner("Random Forest modeli eÄŸitiliyor..."):
            # Veriyi Ã¶n iÅŸle
            X_train, X_test, y_train, y_test, _, _ = preprocess_data(df, 'target', test_size=0.3)
            
            # Modeli oluÅŸtur ve eÄŸit
            rf = RandomForestClassifier(
                n_estimators=n_estimators,
                max_depth=max_depth,
                random_state=42
            )
            rf.fit(X_train, y_train)
            
            # Modelin performansÄ±nÄ± deÄŸerlendir
            train_score = rf.score(X_train, y_train)
            test_score = rf.score(X_test, y_test)
            
            # SkorlarÄ± gÃ¶ster
            st.write(f"**EÄŸitim Seti DoÄŸruluÄŸu:** {train_score:.4f}")
            st.write(f"**Test Seti DoÄŸruluÄŸu:** {test_score:.4f}")
            
            # Ã–zellik Ã¶nemini hesapla
            importances = rf.feature_importances_
            feature_importance = pd.DataFrame({
                'feature': feature_names,
                'importance': importances
            }).sort_values('importance', ascending=False)
            
            # Ã–zellik Ã¶nemini gÃ¶rselleÅŸtir
            st.subheader("Ã–zellik Ã–nemi")
            
            # Statik ve interaktif grafikleri gÃ¶ster
            fig = plot_feature_importance(feature_importance)
            st.pyplot(fig)
            
            st.subheader("Ä°nteraktif Ã–zellik Ã–nemi")
            interactive_fig = plot_interactive_feature_importance(feature_importance)
            st.plotly_chart(interactive_fig, use_container_width=True)
            
            # Ã–zellik Ã¶nemini tablo olarak gÃ¶ster
            st.subheader("Ã–zellik Ã–nemi Tablosu")
            st.dataframe(feature_importance, use_container_width=True)
    
    # PermÃ¼tasyon Ã¶nemi
    else:  # PermÃ¼tasyon Ã–nemi
        st.subheader("PermÃ¼tasyon Ã–nemi")
        st.markdown("""
        PermÃ¼tasyon Ã¶nemi, bir Ã¶zelliÄŸin model performansÄ±na katkÄ±sÄ±nÄ± Ã¶lÃ§mek iÃ§in kullanÄ±lan model-agnostik bir yÃ¶ntemdir.
        Bu yÃ¶ntem, bir Ã¶zelliÄŸin deÄŸerlerini rastgele karÄ±ÅŸtÄ±rarak o Ã¶zelliÄŸin model performansÄ±na etkisini Ã¶lÃ§er.
        """)
        
        # Model seÃ§imi
        model_type = st.selectbox(
            "Baz Model SeÃ§imi",
            options=["Random Forest", "Logistic Regression"],
            index=0
        )
        
        # PermÃ¼tasyon yineleme sayÄ±sÄ±
        n_repeats = st.slider("PermÃ¼tasyon Yineleme SayÄ±sÄ±", min_value=1, max_value=30, value=10, step=1)
        
        # PermÃ¼tasyon Ã¶nemi hesapla
        with st.spinner("PermÃ¼tasyon Ã¶nemi hesaplanÄ±yor..."):
            # Veriyi Ã¶n iÅŸle
            X_train, X_test, y_train, y_test, _, _ = preprocess_data(df, 'target', test_size=0.3)
            
            # Modeli oluÅŸtur ve eÄŸit
            if model_type == "Random Forest":
                from sklearn.ensemble import RandomForestClassifier
                model = RandomForestClassifier(n_estimators=100, random_state=42)
            else:  # Logistic Regression
                from sklearn.linear_model import LogisticRegression
                model = LogisticRegression(random_state=42)
            
            model.fit(X_train, y_train)
            
            # Modelin performansÄ±nÄ± deÄŸerlendir
            train_score = model.score(X_train, y_train)
            test_score = model.score(X_test, y_test)
            
            # SkorlarÄ± gÃ¶ster
            st.write(f"**EÄŸitim Seti DoÄŸruluÄŸu:** {train_score:.4f}")
            st.write(f"**Test Seti DoÄŸruluÄŸu:** {test_score:.4f}")
            
            # PermÃ¼tasyon Ã¶nemi hesapla
            perm_importance = permutation_importance(
                model, X_test, y_test, 
                n_repeats=n_repeats, 
                random_state=42
            )
            
            # Ã–zellik Ã¶nemini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
            perm_feature_importance = pd.DataFrame({
                'feature': feature_names,
                'importance': perm_importance.importances_mean
            }).sort_values('importance', ascending=False)
            
            # Ã–zellik Ã¶nemini gÃ¶rselleÅŸtir
            st.subheader("PermÃ¼tasyon Ã–nemi")
            
            # Statik ve interaktif grafikleri gÃ¶ster
            fig = plot_feature_importance(perm_feature_importance)
            st.pyplot(fig)
            
            st.subheader("Ä°nteraktif PermÃ¼tasyon Ã–nemi")
            interactive_fig = plot_interactive_feature_importance(perm_feature_importance)
            st.plotly_chart(interactive_fig, use_container_width=True)
            
            # Ã–zellik Ã¶nemini tablo olarak gÃ¶ster
            st.subheader("PermÃ¼tasyon Ã–nemi Tablosu")
            st.dataframe(perm_feature_importance, use_container_width=True)
            
            # PermÃ¼tasyon Ã¶neminin standart sapmasÄ±nÄ± gÃ¶rselleÅŸtir
            st.subheader("PermÃ¼tasyon Ã–nemi Standart SapmasÄ±")
            
            # Standart sapmalarÄ± DataFrame'e ekle
            perm_feature_importance['std'] = perm_importance.importances_std
            
            # Hata Ã§ubuklu grafik
            plt.figure(figsize=(12, 8))
            plt.errorbar(
                x=perm_feature_importance['importance'],
                y=perm_feature_importance['feature'],
                xerr=perm_feature_importance['std'],
                fmt='o',
                capsize=5
            )
            plt.xlabel('PermÃ¼tasyon Ã–nemi')
            plt.ylabel('Ã–zellik')
            plt.title('PermÃ¼tasyon Ã–nemi ve Standart Sapma')
            plt.grid(True, alpha=0.3)
            plt.tight_layout()
            st.pyplot(plt)

elif analysis_type == "Korelasyon Analizi":
    st.header("Ã–zellikler ArasÄ± Korelasyon Analizi")
    
    # Korelasyon Ä±sÄ± haritasÄ±
    st.subheader("Korelasyon IsÄ± HaritasÄ±")
    corr_fig = plot_correlation_heatmap(X)
    st.pyplot(corr_fig)
    
    # En yÃ¼ksek korelasyonlu Ã¶zellikleri gÃ¶ster
    st.subheader("En YÃ¼ksek Korelasyonlu Ã–zellik Ã‡iftleri")
    
    # Korelasyon matrisini hesapla
    corr_matrix = X.corr().abs()
    
    # Ãœst Ã¼Ã§geni sÄ±fÄ±rla (tekrarlarÄ± Ã¶nlemek iÃ§in)
    corr_matrix.values[np.triu_indices_from(corr_matrix, k=1)] = 0
    
    # En yÃ¼ksek korelasyonlu Ã§iftleri bul
    corr_pairs = corr_matrix.unstack().sort_values(ascending=False)
    corr_pairs = corr_pairs[corr_pairs > 0].reset_index()
    corr_pairs.columns = ['Ã–zellik 1', 'Ã–zellik 2', 'Korelasyon']
    
    # Korelasyon tablosunu gÃ¶ster
    st.dataframe(corr_pairs.head(15), use_container_width=True)
    
    # SeÃ§ili Ã¶zellik Ã§iftinin daÄŸÄ±lÄ±m grafiÄŸi
    st.subheader("Ã–zellik Ã‡ifti DaÄŸÄ±lÄ±m GrafiÄŸi")
    
    # Ã–zellik seÃ§imi
    col1, col2 = st.columns(2)
    with col1:
        feature1 = st.selectbox("Birinci Ã–zellik", options=feature_names, index=0)
    with col2:
        feature2 = st.selectbox("Ä°kinci Ã–zellik", options=feature_names, index=min(1, len(feature_names)-1))
    
    # DaÄŸÄ±lÄ±m grafiÄŸi
    plt.figure(figsize=(10, 8))
    scatter = plt.scatter(X[feature1], X[feature2], c=y, cmap='viridis', alpha=0.7)
    
    # Regresyon Ã§izgisi
    from scipy import stats
    slope, intercept, r_value, p_value, std_err = stats.linregress(X[feature1], X[feature2])
    plt.plot(X[feature1], intercept + slope*X[feature1], 'r', label=f'r = {r_value:.4f}')
    
    plt.xlabel(feature1)
    plt.ylabel(feature2)
    plt.title(f'{feature1} ve {feature2} ArasÄ±ndaki Ä°liÅŸki')
    plt.legend()
    plt.colorbar(scatter, label='Hedef SÄ±nÄ±f')
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    st.pyplot(plt)

elif analysis_type == "Ã–zellik DaÄŸÄ±lÄ±mlarÄ±":
    st.header("Ã–zellik DaÄŸÄ±lÄ±mlarÄ± ve Hedef Ä°liÅŸkisi")
    
    # Ã–zellik seÃ§imi
    selected_feature = st.selectbox("Ã–zellik SeÃ§in", options=feature_names)
    
    # SeÃ§ilen Ã¶zelliÄŸin daÄŸÄ±lÄ±mÄ±
    st.subheader(f"{selected_feature} DaÄŸÄ±lÄ±mÄ± (SÄ±nÄ±fa GÃ¶re)")
    
    # Kutu grafiÄŸi ve daÄŸÄ±lÄ±m grafiÄŸi iÃ§in 2 sÃ¼tunlu dÃ¼zen
    col1, col2 = st.columns(2)
    
    with col1:
        # Kutu grafiÄŸi
        plt.figure(figsize=(10, 6))
        sns.boxplot(x=y, y=X[selected_feature])
        plt.xlabel('Hedef SÄ±nÄ±f (0: Benign, 1: Malignant)')
        plt.ylabel(selected_feature)
        plt.title(f'{selected_feature} Kutu GrafiÄŸi')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(plt)
    
    with col2:
        # DaÄŸÄ±lÄ±m grafiÄŸi
        plt.figure(figsize=(10, 6))
        sns.histplot(data=df, x=selected_feature, hue='target', kde=True, bins=30)
        plt.xlabel(selected_feature)
        plt.ylabel('YoÄŸunluk')
        plt.title(f'{selected_feature} DaÄŸÄ±lÄ±mÄ±')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(plt)
    
    # Ã–zelliÄŸin istatistikleri
    st.subheader(f"{selected_feature} Ä°statistikleri")
    
    # SÄ±nÄ±f bazÄ±nda istatistikler
    stats_df = df.groupby('target')[selected_feature].describe().T
    stats_df.columns = ['Benign (0)', 'Malignant (1)']
    st.dataframe(stats_df, use_container_width=True)
    
    # Ã–zelliÄŸin hedef sÄ±nÄ±f ile iliÅŸkisi
    st.subheader(f"{selected_feature} ve Hedef SÄ±nÄ±f Ä°liÅŸkisi")
    
    # Point-biserial korelasyon (sÃ¼rekli ve ikili deÄŸiÅŸken arasÄ±nda)
    from scipy import stats
    correlation, p_value = stats.pointbiserialr(X[selected_feature], y)
    
    st.write(f"**Point-Biserial Korelasyon:** {correlation:.4f}")
    st.write(f"**p-deÄŸeri:** {p_value:.4g}")
    
    if p_value < 0.05:
        if correlation > 0:
            st.write(f"**SonuÃ§:** {selected_feature} deÄŸeri arttÄ±kÃ§a, malignant olma olasÄ±lÄ±ÄŸÄ± artÄ±yor.")
        else:
            st.write(f"**SonuÃ§:** {selected_feature} deÄŸeri arttÄ±kÃ§a, malignant olma olasÄ±lÄ±ÄŸÄ± azalÄ±yor.")
    else:
        st.write(f"**SonuÃ§:** {selected_feature} ve hedef sÄ±nÄ±f arasÄ±nda istatistiksel olarak anlamlÄ± bir iliÅŸki bulunamadÄ±.")
    
    # Tek deÄŸiÅŸkenli sÄ±nÄ±flandÄ±rma performansÄ±
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.model_selection import cross_val_score
    
    tree = DecisionTreeClassifier(max_depth=3, random_state=42)
    
    # Tekli Ã¶zellik iÃ§in Ã§apraz doÄŸrulama
    cv_scores = cross_val_score(tree, X[[selected_feature]], y, cv=5)
    
    st.write(f"**Tek DeÄŸiÅŸkenli SÄ±nÄ±flandÄ±rma DoÄŸruluÄŸu:** {cv_scores.mean():.4f} Â± {cv_scores.std():.4f}")

else:  # Boyut Ä°ndirgeme
    st.header("Boyut Ä°ndirgeme Analizi")
    
    # Boyut indirgeme yÃ¶ntemi seÃ§imi
    dim_reduction_method = st.radio(
        "Boyut Ä°ndirgeme YÃ¶ntemi",
        ["PCA (Temel BileÅŸen Analizi)", "t-SNE"]
    )
    
    if dim_reduction_method == "PCA (Temel BileÅŸen Analizi)":
        st.subheader("PCA Analizi")
        
        # PCA boyutu seÃ§imi
        pca_dim = st.radio("PCA GÃ¶rselleÅŸtirme Boyutu", options=["2D", "3D"])
        n_components = 2 if pca_dim == "2D" else 3
        
        # PCA gÃ¶rselleÅŸtirme
        pca_fig = plot_pca_visualization(X.values, y.values, n_components)
        st.pyplot(pca_fig)
        
        st.markdown("""
        **PCA (Temel BileÅŸen Analizi) Nedir?**
        
        Temel BileÅŸen Analizi, yÃ¼ksek boyutlu verileri daha dÃ¼ÅŸÃ¼k boyutlu bir uzaya dÃ¶nÃ¼ÅŸtÃ¼ren bir boyut indirgeme tekniÄŸidir.
        Bu gÃ¶rselleÅŸtirme, verilerin en Ã§ok varyans gÃ¶sterdiÄŸi yÃ¶nleri (temel bileÅŸenleri) kullanarak verilerinizi 2D veya 3D olarak gÃ¶sterir.
        
        - Birbirine yakÄ±n noktalar, orijinal yÃ¼ksek boyutlu uzayda da benzer Ã¶zelliklere sahiptir.
        - FarklÄ± renkler farklÄ± hedef sÄ±nÄ±flarÄ± temsil eder.
        - Temel bileÅŸenlerin yanÄ±ndaki yÃ¼zde deÄŸerleri, o bileÅŸenin toplam varyansÄ±n ne kadarÄ±nÄ± aÃ§Ä±kladÄ±ÄŸÄ±nÄ± gÃ¶sterir.
        """)
        
        # Top 10 Ã¶zelliÄŸin PCA bileÅŸenlerine katkÄ±sÄ±nÄ± gÃ¶ster
        st.subheader("PCA BileÅŸen YÃ¼kleri (Component Loadings)")
        
        from sklearn.decomposition import PCA
        
        # PCA hesapla
        pca = PCA(n_components=min(3, X.shape[1]))
        pca.fit(X)
        
        # BileÅŸen yÃ¼klerini DataFrame'e dÃ¶nÃ¼ÅŸtÃ¼r
        component_names = [f"PC{i+1}" for i in range(pca.n_components_)]
        loadings = pd.DataFrame(
            pca.components_.T,
            columns=component_names,
            index=feature_names
        )
        
        # Her bileÅŸen iÃ§in en Ã¶nemli 10 Ã¶zelliÄŸi gÃ¶ster
        for i, component in enumerate(component_names):
            st.write(f"**{component} Ä°Ã§in En Ã–nemli 10 Ã–zellik:**")
            
            # Mutlak deÄŸer olarak en bÃ¼yÃ¼k yÃ¼kleri al
            top_features = loadings[component].abs().sort_values(ascending=False).head(10)
            
            # Grafik Ã§iz
            plt.figure(figsize=(10, 6))
            colors = ['red' if loadings.loc[feat, component] < 0 else 'blue' for feat in top_features.index]
            plt.barh(top_features.index, top_features.values, color=colors)
            plt.xlabel(f'{component} YÃ¼kleri')
            plt.ylabel('Ã–zellikler')
            plt.title(f'En YÃ¼ksek {component} YÃ¼kleri')
            plt.tight_layout()
            st.pyplot(plt)
        
        # BileÅŸenlerin aÃ§Ä±kladÄ±ÄŸÄ± varyans
        st.subheader("PCA BileÅŸenlerinin AÃ§Ä±kladÄ±ÄŸÄ± Varyans")
        
        # Varyans grafiÄŸi
        plt.figure(figsize=(10, 6))
        plt.bar(component_names, pca.explained_variance_ratio_ * 100)
        plt.xlabel('Temel BileÅŸenler')
        plt.ylabel('AÃ§Ä±klanan Varyans YÃ¼zdesi')
        plt.title('Her BileÅŸenin AÃ§Ä±kladÄ±ÄŸÄ± Varyans YÃ¼zdesi')
        plt.tight_layout()
        st.pyplot(plt)
        
        # KÃ¼mÃ¼latif varyans grafiÄŸi
        plt.figure(figsize=(10, 6))
        plt.plot(range(1, len(component_names) + 1), np.cumsum(pca.explained_variance_ratio_ * 100), marker='o')
        plt.xlabel('BileÅŸen SayÄ±sÄ±')
        plt.ylabel('KÃ¼mÃ¼latif AÃ§Ä±klanan Varyans YÃ¼zdesi')
        plt.title('KÃ¼mÃ¼latif AÃ§Ä±klanan Varyans')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        st.pyplot(plt)
        
    else:  # t-SNE
        st.subheader("t-SNE Analizi")
        
        # t-SNE parametreleri
        col1, col2 = st.columns(2)
        with col1:
            perplexity = st.slider("Perplexity", min_value=5, max_value=50, value=30, step=5)
        with col2:
            n_iter = st.slider("Ä°terasyon SayÄ±sÄ±", min_value=250, max_value=1000, value=300, step=50)
        
        # t-SNE gÃ¶rselleÅŸtirme
        with st.spinner("t-SNE hesaplanÄ±yor... Bu iÅŸlem biraz zaman alabilir."):
            from utils.visualizations import plot_tsne_visualization
            
            tsne_fig = plot_tsne_visualization(X.values, y.values, perplexity=perplexity, n_iter=n_iter)
            st.pyplot(tsne_fig)
        
        st.markdown("""
        **t-SNE (t-Distributed Stochastic Neighbor Embedding) Nedir?**
        
        t-SNE, yÃ¼ksek boyutlu verileri dÃ¼ÅŸÃ¼k boyutlu bir uzaya dÃ¶nÃ¼ÅŸtÃ¼rmek iÃ§in kullanÄ±lan bir boyut indirgeme tekniÄŸidir.
        PCA'dan farklÄ± olarak, t-SNE Ã¶zellikle verilerdeki yerel benzerlikleri korumayÄ± amaÃ§lar.
        
        - Birbirine yakÄ±n noktalar, orijinal yÃ¼ksek boyutlu uzayda da benzerdir.
        - FarklÄ± renkler farklÄ± hedef sÄ±nÄ±flarÄ± temsil eder.
        - t-SNE, veri kÃ¼melerini ayÄ±rmada PCA'dan daha baÅŸarÄ±lÄ± olabilir, ancak her Ã§alÄ±ÅŸtÄ±rmada farklÄ± sonuÃ§lar Ã¼retebilir.
        
        **Parametreler:**
        - **Perplexity:** Yerel komÅŸuluk boyutunu kontrol eder. DÃ¼ÅŸÃ¼k deÄŸerler kÃ¼Ã§Ã¼k yerel yapÄ±lara odaklanÄ±rken, 
          yÃ¼ksek deÄŸerler daha geniÅŸ yapÄ±lara odaklanÄ±r.
        - **Ä°terasyon SayÄ±sÄ±:** AlgoritmanÄ±n Ã§alÄ±ÅŸacaÄŸÄ± adÄ±m sayÄ±sÄ±. Daha yÃ¼ksek deÄŸerler daha iyi sonuÃ§lar verebilir,
          ancak hesaplama sÃ¼resi artar.
        """)
        
        st.warning("""
        Not: t-SNE sonuÃ§larÄ± her Ã§alÄ±ÅŸtÄ±rmada farklÄ± olabilir ve perplexity parametresine oldukÃ§a duyarlÄ±dÄ±r.
        AyrÄ±ca, t-SNE global yapÄ±yÄ± korumak yerine yerel yapÄ±yÄ± korumaya odaklandÄ±ÄŸÄ±ndan, 
        uzak noktalar arasÄ±ndaki iliÅŸkiler her zaman doÄŸru ÅŸekilde temsil edilmeyebilir.
        """)
